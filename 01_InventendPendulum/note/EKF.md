### 扩展卡尔曼滤波 (EKF) 详细推导

为了不跳步骤，我们从最原始的非线性系统定义开始。

#### 1. 定义非线性系统模型

在标准 KF 中，我们有 $x_k = Ax_{k-1} + Bu_k$。但在 EKF 中，我们面对的是一般化的非线性函数。

状态方程（真实世界）：
$$
x_k = f(x_{k-1}, u_k) + w_{k-1}
$$

- $x_k$: $k$ 时刻的状态向量（例如：位置、速度、角度）。
- $f(\cdot)$: 非线性状态转移函数（例如：车辆运动学方程）。
- $u_k$: 控制输入。
- $w_{k-1}$: 过程噪声，假设服从高斯分布 $N(0, Q)$。

观测方程（传感器）：
$$
z_k = h(x_k) + v_k
$$

- $z_k$: 测量值向量（例如：雷达测得的距离和方位角）。
- $h(\cdot)$: 非线性观测函数（把状态映射到测量值的关系）。
- $v_k$: 测量噪声，假设服从高斯分布 $N(0, R)$。

------

#### 2. 核心难题：如何传播高斯分布？

卡尔曼滤波的核心是维护两个东西：

1. **均值**（最佳估计 $\hat{x}$）。
2. **协方差矩阵**（不确定性 $P$）。

**不需要了解的数学（太深奥）：**

> 对于非线性函数 $y = f(x)$，如果 $x$ 是高斯的，那么 $y$ 通常不是高斯的。精确计算 $y$ 的概率密度函数极其复杂（涉及 Fokker-Planck 方程等）。
>
> 工程师的应对： 我们放弃追求完美的概率分布，转而使用近似。我们假设变换后的分布依然是高斯的，只计算变换后的“近似均值”和“近似方差”。

------

#### 3. 预测步骤（Time Update）推导

这是最关键的一步：**线性化**。

第一步：状态均值的预测

我们直接将上一时刻的最优估计代入非线性函数。这里没有任何花哨的数学，就是代入：
$$
\hat{x}_k^- = f(\hat{x}_{k-1}, u_k)
$$
(注：上标 “-” 代表先验估计，即校正前的值；$\hat{x}_{k-1}$ 是上一时刻的后验估计)

第二步：协方差矩阵 $P$ 的预测

我们需要计算 $P_k^-$。根据协方差定义：
$$
P_k^- = E \left[ (x_k - \hat{x}_k^-)(x_k - \hat{x}_k^-)^T \right]
$$
即：先验预测误差的期望。

为了计算这个，我们需要找到 $x_k$（真实值）和 $\hat{x}_k^-$（先验预测值）之间的关系。

由于 $f(\cdot)$ 是非线性的，我们无法直接相减。这时，泰勒级数展开登场。

我们将非线性函数 $f(x_{k-1}, u_k)$ 在**上一时刻的最优估计点 $\hat{x}_{k-1}$** 处展开：
$$
f(x_{k-1}, u_k) \approx f(\hat{x}_{k-1}, u_k) + \left. \frac{\partial f}{\partial x} \right|_{x=\hat{x}_{k-1}} (x_{k-1} - \hat{x}_{k-1}) + \text{高阶项}
$$

- $f(\hat{x}_{k-1}, u_k)$ 就是我们的预测值 $\hat{x}_k^-$。
- $\left. \frac{\partial f}{\partial x} \right|_{x=\hat{x}_{k-1}}$ 是**雅可比矩阵**，我们记为 $F_{k-1}$。
- $(x_{k-1} - \hat{x}_{k-1})$ 是上一时刻的**估计误差**，记为 $e_{k-1}$。

忽略高阶项（这是 EKF 误差的来源），我们将展开式代入真实状态方程：
$$
x_k \approx \underbrace{f(\hat{x}_{k-1}, u_k)}_{\hat{x}_k^-} + F_{k-1}(x_{k-1} - \hat{x}_{k-1}) + w_{k-1}
$$
移项，得到预测误差 $e_k^-$：
$$
e_k^- = x_k - \hat{x}_k^- \approx F_{k-1}(x_{k-1} - \hat{x}_{k-1}) + w_{k-1} \\
e_k^- \approx F_{k-1} e_{k-1} + w_{k-1}
$$
通过泰勒展开，我们把非线性的误差传播方程，变成了线性的形式：误差 $e$ 乘以一个矩阵 $F$。

现在代入协方差公式：
$$
P_k^- = E[e_k^- (e_k^-)^T]\\
P_k^- = E[ (F_{k-1} e_{k-1} + w_{k-1}) (F_{k-1} e_{k-1} + w_{k-1})^T ]
$$
展开括号（利用 $(A+B)(A+B)^T = AA^T + AB^T + BA^T + BB^T$）：
$$
P_k^- = E[ F_{k-1} e_{k-1} e_{k-1}^T F_{k-1}^T + F_{k-1} e_{k-1} w_{k-1}^T + w_{k-1} e_{k-1}^T F_{k-1}^T + w_{k-1} w_{k-1}^T ]
$$
根据统计学性质：

1. $E[e_{k-1} e_{k-1}^T]$ 就是上一时刻的后验协方差 $P_{k-1}$。
2. 误差 $e$ 和噪声 $w$ 是不相关的（独立的），所以交叉项 $E[e w^T] = 0$。
3. $E[w w^T]$ 是过程噪声协方差矩阵 $Q$。

最终得到预测协方差公式：
$$
P_k^- = F_{k-1} P_{k-1} F_{k-1}^T + Q
$$

------

#### 4. 更新步骤（Measurement Update）推导

逻辑与预测步骤完全一致，只是这次我们要对观测方程 $h(x)$ 进行线性化。

第一步：测量残差（Innovation）

我们需要对比“传感器实测值 $z_k$”和“根据模型预测的测量值”。

预测的测量值：$h(\hat{x}_k^-)$。

同样，因为 $h(x)$ 是非线性的，我们需要对 $h(x_k)$ 在先验估计 $\hat{x}_k^-$ 处进行泰勒展开：
$$
z(x_k) \approx h(\hat{x}_k^-) + \left. \frac{\partial h}{\partial x} \right|_{x=\hat{x}_k^-} (x_k - \hat{x}_k^-) + v_k
$$
定义雅可比矩阵 $H_k = \left. \frac{\partial h}{\partial x} \right|_{x=\hat{x}_k^-}$。

测量残差 $\tilde{y}_k$ 为：
$$
\tilde{y}_k = z_k - h(\hat{x}_k^-)
$$
代入展开式：
$$
\tilde{y}_k \approx H_k (x_k - \hat{x}_k^-) + v_k = H_k e_k^- + v_k
$$
第二步：卡尔曼增益 $K_k$

这里我们直接沿用标准 KF 的结论。因为经过上面的线性化，我们已经把问题构建成了：

- 状态误差：$e_k^- \sim N(0, P_k^-)$
- 测量误差线性关系：$\tilde{y}_k = H_k e_k^- + v_k$

**不需要了解的数学（数学家做的事）：**

> 如何通过最小化均方误差（MMSE）或者最大似然估计（MLE）来推导 $K$ 的最优形式。对于 GNC 工程师，你只需要知道：在线性高斯假设下，这个 $K$ 的形式是数学上最优的权重分配。

卡尔曼增益公式（直接套用 KF 公式，将 $H$ 替换为雅可比矩阵 $H_k$）：$K_k$，先写出后验误差协方差 $P_k$ 的表达式，中途也会得到**Joseph form**，然后对它求导，令导数为 0，即可获得
$$
K_k = P_k^- H_k^T (H_k P_k^- H_k^T + R)^{-1}
$$
第三步：状态更新
$$
\hat{x}_k = \hat{x}_k^- + K_k (z_k - h(\hat{x}_k^-))
$$
第四步：协方差更新
$$
P_k = (I - K_k H_k) P_k^-
$$
**Joseph form（约瑟夫形式）**：虽然我们在最后会用上面的简化公式，但在实际工程代码（C++/C）中，有时候为了**数值稳定性**（防止计算机浮点数误差导致 $P$ 矩阵不对称或变为负定），我们会直接使用这个复杂的 Joseph 形式来更新协方差，因为它天生保证了对称正定性。
$$
P_k = (I - K_k H_k) P_k^- (I - K_k H_k)^T + K_k R K_k^T
$$
将最优 $K_k$ 代回 Joseph 方程。

这里有一个代数技巧：

我们知道最优增益满足：$K_k (H_k P_k^- H_k^T + R) = P_k^- H_k^T$，也就是：$K_k R = P_k^- H_k^T - K_k H_k P_k^- H_k^T$

把这个 $K_k R$ 代入 Joseph 形式的最后一项 $K_k R K_k^T$ 中：
$$
P_k = (I - K_k H_k) P_k^- (I - K_k H_k)^T + K_k R K_k^T
$$
化简后即可得到最上面的公式。